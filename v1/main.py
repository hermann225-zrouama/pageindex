# main.py
import argparse
import json
from datetime import datetime
from pathlib import Path
from vector_retriever import VectorRetriever
from retriever_manager import RetrieverManager
from rag_pipeline import RAGPipeline


def process_single_query(pipeline, query, args):
    """Traite une seule requ√™te et retourne le r√©sultat"""
    result = pipeline.answer(
        query=query,
        chunks_per_primary=args.chunks_per_primary,
        chunks_per_fallback=args.chunks_per_fallback,
        max_chunk_length=args.max_chunk_length,
        use_hyde=args.use_hyde,
        use_query_expansion=not args.no_expansion
    )
    return result


def display_single_result(result):
    """Affiche le r√©sultat d'une seule requ√™te"""
    print("\n" + "="*60)
    print("üéØ R√âPONSE")
    print("="*60)
    print(result["answer"])
    
    print("\n" + "="*60)
    print("üìä STATISTIQUES")
    print("="*60)
    print(f"  ‚Ä¢ Retriever: {result['retriever_used']}")
    print(f"  ‚Ä¢ Chunks: {result['num_chunks']}")
    print(f"  ‚Ä¢ Contexte: ~{result['total_context_chars']} chars")
    print(f"  ‚Ä¢ Variantes: {len(result['query_variants'])}")
    
    print("\n" + "="*60)
    print("üìö DOCUMENTS")
    print("="*60)
    print("\nPRIMARY:")
    for doc in result["primary_docs"]:
        print(f"  ‚Ä¢ {doc['doc_name']}")
    
    if result["fallback_docs"]:
        print("\nFALLBACK:")
        for doc in result["fallback_docs"]:
            print(f"  ‚Ä¢ {doc['doc_name']}")


def format_result_to_markdown(query_idx, query, result):
    """Formate un r√©sultat en markdown"""
    md_content = f"## Question {query_idx + 1}\n\n"
    md_content += f"**Query:** {query}\n\n"
    md_content += f"### R√©ponse\n\n{result['answer']}\n\n"
    md_content += f"### Statistiques\n\n"
    md_content += f"- **Retriever:** {result['retriever_used']}\n"
    md_content += f"- **Chunks:** {result['num_chunks']}\n"
    md_content += f"- **Contexte:** ~{result['total_context_chars']} chars\n"
    md_content += f"- **Variantes:** {len(result['query_variants'])}\n\n"
    
    md_content += f"### Documents Utilis√©s\n\n"
    md_content += "**PRIMARY:**\n\n"
    for doc in result["primary_docs"]:
        md_content += f"- {doc['doc_name']}\n"
    
    if result["fallback_docs"]:
        md_content += "\n**FALLBACK:**\n\n"
        for doc in result["fallback_docs"]:
            md_content += f"- {doc['doc_name']}\n"
    
    md_content += "\n---\n\n"
    return md_content


def process_questionnaire(pipeline, questionnaire_path, args):
    """Traite un fichier questionnaire JSON et g√©n√®re answers.md"""
    # Charger le fichier JSON
    with open(questionnaire_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    queries = data.get("queries", [])
    
    if not queries:
        print("‚ùå Aucune requ√™te trouv√©e dans le fichier JSON")
        return
    
    print(f"üìã {len(queries)} requ√™tes √† traiter...\n")
    
    # Pr√©parer le contenu Markdown
    md_content = f"# R√©sultats du Questionnaire\n\n"
    md_content += f"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    md_content += f"**Nombre de questions:** {len(queries)}\n\n"
    md_content += "---\n\n"
    
    # Traiter chaque requ√™te
    for idx, query in enumerate(queries):
        print(f"[{idx + 1}/{len(queries)}] Traitement: {query[:80]}...")
        
        try:
            result = process_single_query(pipeline, query, args)
            md_content += format_result_to_markdown(idx, query, result)
            print(f"‚úÖ Question {idx + 1} trait√©e avec succ√®s")
        except Exception as e:
            print(f"‚ùå Erreur pour la question {idx + 1}: {str(e)}")
            md_content += f"## Question {idx + 1}\n\n"
            md_content += f"**Query:** {query}\n\n"
            md_content += f"### Erreur\n\n{str(e)}\n\n---\n\n"
    
    # √âcrire le fichier answers.md
    output_path = Path("answers.md")
    output_path.write_text(md_content, encoding='utf-8')
    
    print(f"\n‚úÖ Fichier g√©n√©r√©: {output_path.absolute()}")


def main():
    parser = argparse.ArgumentParser(description="RAG Pipeline Modulaire")
    
    # Mode questionnaire ou requ√™te unique
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--query", type=str, help="Requ√™te unique √† traiter")
    group.add_argument("--questionnaire", type=str, help="Chemin vers le fichier JSON de questions")
    
    # Param√®tres du pipeline
    parser.add_argument("--chunks-per-primary", type=int, default=4)
    parser.add_argument("--chunks-per-fallback", type=int, default=0)
    parser.add_argument("--max-chunk-length", type=int, default=500)
    parser.add_argument("--use-hyde", action="store_true", default=False)
    parser.add_argument("--no-expansion", action="store_true")
    
    args = parser.parse_args()
    
    # 1. Cr√©e le retriever manager
    manager = RetrieverManager()
    
    # 2. Enregistre le VectorRetriever
    vector_retriever = VectorRetriever(
        index_path="data/index_faiss.npz",
        data_dir="data"
    )
    manager.register(vector_retriever, set_as_default=True)
    
    # 3. Cr√©e le pipeline RAG
    pipeline = RAGPipeline(
        manager, 
        data_dir="data", 
        mistral_api_key="rUqtUW7Az9sYVdRQI3Lo2Y6QWdIrVp4b"
    )
    
    # 4. Execute selon le mode
    if args.questionnaire:
        process_questionnaire(pipeline, args.questionnaire, args)
    else:
        result = process_single_query(pipeline, args.query, args)
        display_single_result(result)


if __name__ == "__main__":
    main()
